import tensorflow as tf
from keras import models, layers
import numpy as np
from sklearn.svm import SVC
from sklearn.decomposition import PCA

# Load and preprocess your data
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train = x_train.reshape((-1, 28, 28, 1)).astype('float32') / 255.0
x_test = x_test.reshape((-1, 28, 28, 1)).astype('float32') / 255.0

# Convert target data to the appropriate format
num_classes = 10  # Number of classes in the MNIST dataset
y_train = tf.keras.utils.to_categorical(y_train, num_classes)
y_test = tf.keras.utils.to_categorical(y_test, num_classes)

# Define the original model
model = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),  # Increased filters to 64
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),  # Increased filters to 128
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),  # Increased filters to 128
    layers.Flatten(),
    layers.Dense(128, activation='relu'),  # Changed dense layer size to 128
    layers.Dropout(0.5),  # Added dropout layer for regularization
    layers.Dense(10, activation='softmax')  # Output layer with softmax activation for 10 classes
])


# Compile and train the original model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))

test_loss, test_accurray = model.evaluate(x_test, y_test)
print('Test accuracy:',test_accurray)



# Create a new model to extract features from the 3rd convolutional layer
conv_layer_model = models.Model(inputs=model.inputs, outputs=model.layers[2].output)

# Extract convolutional features from the training set
train_features = conv_layer_model.predict(x_train)
test_features = conv_layer_model.predict(x_test)

# Reshape the features for SVM input
train_features_reshaped = train_features.reshape(train_features.shape[0], -1)
test_features_reshaped = test_features.reshape(test_features.shape[0], -1)

# Apply PCA for dimensionality reduction
pca = PCA(n_components=100)  # You can adjust the number of components as needed
train_features_pca = pca.fit_transform(train_features_reshaped)
test_features_pca = pca.transform(test_features_reshaped)

# SVM model
svm_model = SVC()
svm_model.fit(train_features_pca, np.argmax(y_train, axis=1))

# Evaluate SVM model
svm_accuracy = svm_model.score(test_features_pca, np.argmax(y_test, axis=1))
print('SVM accuracy:', svm_accuracy)

# Default value for HOG+SVM test accuracy
hog_svm_test_accuracy = None

# Load accuracy for HOG+SVM model from Assignment 2
# Assuming you have already saved the accuracy in a file called 'Accuracy_HOG_SVM.txt'
with open('Accuracy 0.963.txt', 'r') as f:
    lines = f.readlines()
    if lines:  # Check if lines exist
        hog_svm_test_accuracy = float(lines[0].split(': ')[1])
    else:
        print("Error: No lines in the file 'Accuracy_HOG_SVM.txt'.")

# Compare accuracies of CNN+SVM and HOG+SVM models
print("CNN+SVM Model Accuracy:")
print("Test Accuracy:", svm_accuracy)
print("\nHOG+SVM Model Accuracy:")
print("Test Accuracy:", hog_svm_test_accuracy)

# Compare and print the comparison result
if svm_accuracy > hog_svm_test_accuracy:
    print("\nCNN+SVM model has higher test accuracy than HOG+SVM model.")
else:
    print("\nHOG+SVM model has higher test accuracy than CNN+SVM model.")
